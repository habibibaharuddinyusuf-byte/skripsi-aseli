{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Penyakit Makula Mata Menggunakan CNN\n",
    "## Deteksi CNV, DME, dan DRUSEN\n",
    "\n",
    "Notebook ini mengimplementasikan model CNN untuk mengklasifikasikan penyakit pada makula mata dari gambar OCT (Optical Coherence Tomography).\n",
    "\n",
    "**Penyakit yang dideteksi:**\n",
    "- **CNV** (Choroidal Neovascularization)\n",
    "- **DME** (Diabetic Macular Edema)\n",
    "- **DRUSEN**\n",
    "- **NORMAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library jika belum terinstall\n",
    "# !pip install tensorflow pillow matplotlib numpy pandas scikit-learn opencv-python seaborn --upgrade\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Konfigurasi Path Dataset\n",
    "\n",
    "Struktur folder dataset yang diharapkan:\n",
    "```\n",
    "dataset/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ CNV/\n",
    "â”‚   â”œâ”€â”€ DME/\n",
    "â”‚   â”œâ”€â”€ DRUSEN/\n",
    "â”‚   â””â”€â”€ NORMAL/\n",
    "â”œâ”€â”€ val/\n",
    "â”‚   â”œâ”€â”€ CNV/\n",
    "â”‚   â”œâ”€â”€ DME/\n",
    "â”‚   â”œâ”€â”€ DRUSEN/\n",
    "â”‚   â””â”€â”€ NORMAL/\n",
    "â””â”€â”€ test/\n",
    "    â”œâ”€â”€ CNV/\n",
    "    â”œâ”€â”€ DME/\n",
    "    â”œâ”€â”€ DRUSEN/\n",
    "    â””â”€â”€ NORMAL/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi Path Dataset\n",
    "BASE_DIR = 'dataset\\d3'  # Ubah sesuai lokasi dataset Anda\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train\\\\train')\n",
    "VAL_DIR = os.path.join(BASE_DIR, 'validation\\\\validation')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test\\\\test')\n",
    "\n",
    "# Verifikasi path dataset\n",
    "print(\"Verifikasi Path Dataset:\")\n",
    "print(f\"Train Directory: {os.path.exists(TRAIN_DIR)} - {TRAIN_DIR}\")\n",
    "print(f\"Validation Directory: {os.path.exists(VAL_DIR)} - {VAL_DIR}\")\n",
    "print(f\"Test Directory: {os.path.exists(TEST_DIR)} - {TEST_DIR}\")\n",
    "\n",
    "# Daftar kelas penyakit\n",
    "CLASSES = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nKelas yang akan diprediksi: {CLASSES}\")\n",
    "print(f\"Jumlah kelas: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter dan Konfigurasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Seed untuk reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"Konfigurasi Model:\")\n",
    "print(f\"Ukuran Gambar: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Eksplorasi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_in_directory(directory):\n",
    "    \"\"\"Menghitung jumlah gambar per kelas dalam direktori\"\"\"\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Direktori {directory} tidak ditemukan!\")\n",
    "        return counts, total\n",
    "    \n",
    "    for class_name in CLASSES:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "            count = len(image_files)\n",
    "            counts[class_name] = count\n",
    "            total += count\n",
    "        else:\n",
    "            counts[class_name] = 0\n",
    "    \n",
    "    return counts, total\n",
    "\n",
    "# Hitung jumlah gambar di setiap set\n",
    "train_counts, train_total = count_images_in_directory(TRAIN_DIR)\n",
    "val_counts, val_total = count_images_in_directory(VAL_DIR)\n",
    "test_counts, test_total = count_images_in_directory(TEST_DIR)\n",
    "\n",
    "# Tampilkan statistik\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTIK DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n{'Kelas':<15} {'Train':<10} {'Validation':<15} {'Test':<10}\")\n",
    "print(\"-\"*60)\n",
    "for class_name in CLASSES:\n",
    "    print(f\"{class_name:<15} {train_counts.get(class_name, 0):<10} \"\n",
    "          f\"{val_counts.get(class_name, 0):<15} {test_counts.get(class_name, 0):<10}\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"{'TOTAL':<15} {train_total:<10} {val_total:<15} {test_total:<10}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi dataset\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets = [\n",
    "    ('Training Set', train_counts),\n",
    "    ('Validation Set', val_counts),\n",
    "    ('Test Set', test_counts)\n",
    "]\n",
    "\n",
    "for idx, (title, counts) in enumerate(datasets):\n",
    "    classes = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "    \n",
    "    axes[idx].bar(classes, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[idx].set_title(title, fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Kelas', fontsize=12)\n",
    "    axes[idx].set_ylabel('Jumlah Gambar', fontsize=12)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Tambahkan nilai di atas bar\n",
    "    for i, v in enumerate(values):\n",
    "        axes[idx].text(i, v + max(values)*0.02, str(v), \n",
    "                      ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fungsi Preprocessing (Konversi ke Grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocessing gambar: konversi ke grayscale dan normalisasi\n",
    "    Input: gambar RGB (H, W, 3)\n",
    "    Output: gambar grayscale (H, W, 1)\n",
    "    \"\"\"\n",
    "    # Konversi ke grayscale menggunakan weighted average (RGB to Gray)\n",
    "    # Formula: Gray = 0.299*R + 0.587*G + 0.114*B\n",
    "    gray = tf.image.rgb_to_grayscale(image)\n",
    "    \n",
    "    # Normalisasi ke range [0, 1]\n",
    "    gray = gray / 255.0\n",
    "    \n",
    "    return gray\n",
    "\n",
    "def preprocess_for_prediction(image_path):\n",
    "    \"\"\"\n",
    "    Preprocessing untuk prediksi gambar baru\n",
    "    \"\"\"\n",
    "    # Load gambar\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Tidak dapat membaca gambar: {image_path}\")\n",
    "    \n",
    "    # Resize\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "    # Konversi BGR ke RGB (OpenCV menggunakan BGR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Konversi ke grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Expand dimensions untuk channel\n",
    "    gray = np.expand_dims(gray, axis=-1)\n",
    "    \n",
    "    # Normalisasi\n",
    "    gray = gray / 255.0\n",
    "    \n",
    "    # Expand dimensions untuk batch\n",
    "    gray = np.expand_dims(gray, axis=0)\n",
    "    \n",
    "    return gray, img\n",
    "\n",
    "print(\"Fungsi preprocessing telah didefinisikan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Generator dengan Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator tanpa augmentasi (sesuai permintaan)\n",
    "# Hanya melakukan rescaling karena preprocessing grayscale dilakukan di model\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=None  # Preprocessing dilakukan di layer model\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    color_mode='rgb'  # Load sebagai RGB, akan dikonversi ke grayscale di model\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "print(f\"\\nData berhasil dimuat!\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisasi Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi beberapa sample dari training set\n",
    "def visualize_samples(generator, num_samples=8):\n",
    "    \"\"\"Visualisasi sample gambar dari generator\"\"\"\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    # Konversi ke grayscale untuk visualisasi\n",
    "    gray_images = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images[:num_samples]])\n",
    "    \n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        axes[idx].imshow(gray_images[idx], cmap='gray')\n",
    "        label_idx = np.argmax(labels[idx])\n",
    "        axes[idx].set_title(f'Kelas: {class_names[label_idx]}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Gambar Training Set (Grayscale)', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Arsitektur Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    \"\"\"\n",
    "    Membuat arsitektur CNN untuk klasifikasi penyakit makula mata\n",
    "    Input: RGB image (224, 224, 3)\n",
    "    Output: 4 classes (CNV, DME, DRUSEN, NORMAL)\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        \n",
    "        # Preprocessing layer: Konversi RGB ke Grayscale\n",
    "        layers.Lambda(lambda x: tf.image.rgb_to_grayscale(x), name='rgb_to_grayscale'),\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool3'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Convolutional Block 4\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool4'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu', name='fc1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu', name='fc2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Buat model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Tampilkan summary model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi arsitektur model\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=96\n",
    ")\n",
    "\n",
    "print(\"Arsitektur model telah disimpan sebagai 'model_architecture.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Callbacks untuk Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat direktori untuk menyimpan model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    # Early Stopping: hentikan training jika tidak ada improvement\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Model Checkpoint: simpan model terbaik\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce Learning Rate: kurangi learning rate jika plateau\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks telah dikonfigurasi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulai training\n",
    "print(\"Memulai training model...\\n\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SELESAI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualisasi Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Visualisasi accuracy dan loss selama training\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend(loc='lower right')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend(loc='upper right')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Validation Precision', linewidth=2)\n",
    "    axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend(loc='lower right')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Validation Recall', linewidth=2)\n",
    "    axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend(loc='lower right')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Evaluasi Model pada Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model pada test set\n",
    "print(\"Evaluasi model pada test set...\\n\")\n",
    "\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HASIL EVALUASI TEST SET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"F1-Score: {2 * (test_precision * test_recall) / (test_precision + test_recall):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Confusion Matrix dan Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi pada test set\n",
    "test_generator.reset()\n",
    "y_pred_probs = model.predict(test_generator, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASSES, yticklabels=CLASSES,\n",
    "            cbar_kws={'label': 'Jumlah Prediksi'})\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Visualisasi Prediksi pada Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(generator, model, num_samples=12):\n",
    "    \"\"\"Visualisasi prediksi model pada sample test set\"\"\"\n",
    "    generator.reset()\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    predictions = model.predict(images[:num_samples])\n",
    "    \n",
    "    # Konversi ke grayscale untuk visualisasi\n",
    "    gray_images = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images[:num_samples]])\n",
    "    \n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        axes[idx].imshow(gray_images[idx], cmap='gray')\n",
    "        \n",
    "        true_label = class_names[np.argmax(labels[idx])]\n",
    "        pred_label = class_names[np.argmax(predictions[idx])]\n",
    "        confidence = np.max(predictions[idx]) * 100\n",
    "        \n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        axes[idx].set_title(\n",
    "            f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%',\n",
    "            fontsize=10,\n",
    "            color=color,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Prediksi Model pada Test Set', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('test_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(test_generator, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model dalam berbagai format\n",
    "print(\"Menyimpan model...\\n\")\n",
    "\n",
    "# Format Keras (recommended)\n",
    "model.save('models/retinal_disease_model.keras')\n",
    "print(\"âœ“ Model disimpan sebagai: models/retinal_disease_model.keras\")\n",
    "\n",
    "# SavedModel format (untuk deployment)\n",
    "model.save('models/retinal_disease_savedmodel')\n",
    "print(\"âœ“ Model disimpan sebagai: models/retinal_disease_savedmodel\")\n",
    "\n",
    "# Simpan weights saja\n",
    "model.save_weights('models/model_weights.weights.h5')\n",
    "print(\"âœ“ Weights disimpan sebagai: models/model_weights.weights.h5\")\n",
    "\n",
    "print(\"\\nSemua model berhasil disimpan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Fungsi Prediksi untuk Gambar Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_image(image_path, model):\n",
    "    \"\"\"\n",
    "    Prediksi penyakit pada gambar baru\n",
    "    Gambar akan otomatis dikonversi ke grayscale sebelum prediksi\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path ke gambar yang akan diprediksi\n",
    "        model: Model yang sudah ditraining\n",
    "    \n",
    "    Returns:\n",
    "        predicted_class: Kelas yang diprediksi\n",
    "        confidence: Tingkat kepercayaan prediksi\n",
    "        all_probabilities: Probabilitas untuk semua kelas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocessing gambar\n",
    "        processed_img, original_img = preprocess_for_prediction(image_path)\n",
    "        \n",
    "        # Prediksi\n",
    "        predictions = model.predict(processed_img, verbose=0)\n",
    "        \n",
    "        # Hasil prediksi\n",
    "        predicted_class_idx = np.argmax(predictions[0])\n",
    "        predicted_class = CLASSES[predicted_class_idx]\n",
    "        confidence = predictions[0][predicted_class_idx] * 100\n",
    "        \n",
    "        # Probabilitas semua kelas\n",
    "        all_probabilities = {CLASSES[i]: predictions[0][i] * 100 for i in range(NUM_CLASSES)}\n",
    "        \n",
    "        return predicted_class, confidence, all_probabilities, original_img, processed_img\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memproses gambar: {str(e)}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "def visualize_prediction(image_path, model):\n",
    "    \"\"\"\n",
    "    Visualisasi hasil prediksi untuk gambar baru\n",
    "    \"\"\"\n",
    "    predicted_class, confidence, all_probs, original_img, processed_img = predict_new_image(image_path, model)\n",
    "    \n",
    "    if predicted_class is None:\n",
    "        return\n",
    "    \n",
    "    # Plot hasil\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Gambar original\n",
    "    axes[0].imshow(original_img)\n",
    "    axes[0].set_title('Gambar Original (RGB)', fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Gambar grayscale\n",
    "    axes[1].imshow(processed_img[0, :, :, 0], cmap='gray')\n",
    "    axes[1].set_title('Gambar Grayscale (Input Model)', fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Bar chart probabilitas\n",
    "    classes = list(all_probs.keys())\n",
    "    probabilities = list(all_probs.values())\n",
    "    colors = ['#FF6B6B' if c == predicted_class else '#95A5A6' for c in classes]\n",
    "    \n",
    "    bars = axes[2].barh(classes, probabilities, color=colors)\n",
    "    axes[2].set_xlabel('Probabilitas (%)', fontsize=12)\n",
    "    axes[2].set_title('Probabilitas Prediksi', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_xlim(0, 100)\n",
    "    \n",
    "    # Tambahkan nilai di ujung bar\n",
    "    for i, (bar, prob) in enumerate(zip(bars, probabilities)):\n",
    "        axes[2].text(prob + 2, i, f'{prob:.2f}%', \n",
    "                    va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print hasil\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HASIL PREDIKSI\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Gambar: {os.path.basename(image_path)}\")\n",
    "    print(f\"Prediksi: {predicted_class}\")\n",
    "    print(f\"Tingkat Kepercayaan: {confidence:.2f}%\")\n",
    "    print(\"\\nProbabilitas untuk semua kelas:\")\n",
    "    for class_name, prob in sorted(all_probs.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {class_name}: {prob:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "print(\"Fungsi prediksi telah didefinisikan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Contoh Prediksi Gambar Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh penggunaan prediksi gambar baru\n",
    "# Ganti path dengan gambar yang ingin diprediksi\n",
    "\n",
    "# Contoh 1: Prediksi satu gambar\n",
    "NEW_IMAGE_PATH = 'path/to/your/new_image.jpg'  # Ubah dengan path gambar Anda\n",
    "\n",
    "# Uncomment baris di bawah untuk menjalankan prediksi\n",
    "# visualize_prediction(NEW_IMAGE_PATH, model)\n",
    "\n",
    "print(\"Untuk memprediksi gambar baru:\")\n",
    "print(\"1. Ubah variable NEW_IMAGE_PATH dengan path gambar Anda\")\n",
    "print(\"2. Uncomment baris visualize_prediction()\")\n",
    "print(\"3. Jalankan cell ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Batch Prediction untuk Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(image_folder, model, output_csv='predictions.csv'):\n",
    "    \"\"\"\n",
    "    Prediksi batch untuk multiple images dalam satu folder\n",
    "    \n",
    "    Args:\n",
    "        image_folder: Folder berisi gambar-gambar yang akan diprediksi\n",
    "        model: Model yang sudah ditraining\n",
    "        output_csv: Nama file CSV untuk menyimpan hasil\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Ambil semua file gambar\n",
    "    image_files = [f for f in os.listdir(image_folder) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    \n",
    "    print(f\"Ditemukan {len(image_files)} gambar untuk diprediksi...\\n\")\n",
    "    \n",
    "    for idx, image_file in enumerate(image_files, 1):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        \n",
    "        predicted_class, confidence, all_probs, _, _ = predict_new_image(image_path, model)\n",
    "        \n",
    "        if predicted_class:\n",
    "            result = {\n",
    "                'filename': image_file,\n",
    "                'predicted_class': predicted_class,\n",
    "                'confidence': f\"{confidence:.2f}%\"\n",
    "            }\n",
    "            \n",
    "            # Tambahkan probabilitas untuk setiap kelas\n",
    "            for class_name, prob in all_probs.items():\n",
    "                result[f'prob_{class_name}'] = f\"{prob:.2f}%\"\n",
    "            \n",
    "            results.append(result)\n",
    "            print(f\"[{idx}/{len(image_files)}] {image_file}: {predicted_class} ({confidence:.2f}%)\")\n",
    "    \n",
    "    # Simpan ke CSV\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nâœ“ Hasil prediksi disimpan ke: {output_csv}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Tidak ada prediksi yang berhasil.\")\n",
    "        return None\n",
    "\n",
    "# Contoh penggunaan\n",
    "# NEW_IMAGES_FOLDER = 'path/to/your/images/folder'\n",
    "# predictions_df = batch_predict(NEW_IMAGES_FOLDER, model)\n",
    "# print(predictions_df)\n",
    "\n",
    "print(\"Fungsi batch prediction telah didefinisikan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Load Model yang Sudah Disimpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menggunakan model yang sudah disimpan di lain waktu\n",
    "def load_trained_model(model_path='models/best_model.keras'):\n",
    "    \"\"\"\n",
    "    Load model yang sudah ditraining sebelumnya\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"âœ“ Model berhasil dimuat dari: {model_path}\")\n",
    "        return loaded_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memuat model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Contoh penggunaan:\n",
    "# loaded_model = load_trained_model('models/best_model.keras')\n",
    "# visualize_prediction('path/to/image.jpg', loaded_model)\n",
    "\n",
    "print(\"Fungsi load model telah didefinisikan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Summary dan Informasi Penggunaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY - SISTEM KLASIFIKASI PENYAKIT MAKULA MATA\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nðŸ“‹ INFORMASI MODEL:\")\n",
    "print(f\"  â€¢ Jenis Model: Convolutional Neural Network (CNN)\")\n",
    "print(f\"  â€¢ Input: Gambar RGB (224x224x3) â†’ Otomatis dikonversi ke Grayscale\")\n",
    "print(f\"  â€¢ Output: 4 Kelas (CNV, DME, DRUSEN, NORMAL)\")\n",
    "print(f\"  â€¢ Framework: TensorFlow {tf.__version__} / Keras {keras.__version__}\")\n",
    "\n",
    "print(\"\\nðŸ“Š PERFORMA MODEL:\")\n",
    "print(f\"  â€¢ Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"  â€¢ Test Precision: {test_precision:.4f}\")\n",
    "print(f\"  â€¢ Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¾ FILE YANG DISIMPAN:\")\n",
    "print(\"  â€¢ models/best_model.keras - Model terbaik\")\n",
    "print(\"  â€¢ models/retinal_disease_model.keras - Model final\")\n",
    "print(\"  â€¢ models/model_weights.weights.h5 - Weights model\")\n",
    "print(\"  â€¢ training_history.png - Grafik training\")\n",
    "print(\"  â€¢ confusion_matrix.png - Confusion matrix\")\n",
    "print(\"  â€¢ test_predictions.png - Visualisasi prediksi\")\n",
    "\n",
    "print(\"\\nðŸ”§ CARA MENGGUNAKAN UNTUK PREDIKSI:\")\n",
    "print(\"\"\"  \n",
    "  # 1. Load model\n",
    "  model = load_trained_model('models/best_model.keras')\n",
    "  \n",
    "  # 2. Prediksi satu gambar\n",
    "  visualize_prediction('path/to/image.jpg', model)\n",
    "  \n",
    "  # 3. Prediksi batch (multiple images)\n",
    "  batch_predict('path/to/folder/', model, 'results.csv')\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâš ï¸  CATATAN PENTING:\")\n",
    "print(\"  â€¢ Gambar baru akan OTOMATIS dikonversi ke GRAYSCALE sebelum prediksi\")\n",
    "print(\"  â€¢ Pastikan gambar memiliki resolusi yang cukup baik\")\n",
    "print(\"  â€¢ Model telah dioptimalkan untuk gambar OCT retina\")\n",
    "print(\"  â€¢ Tidak ada augmentasi data (sesuai permintaan)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ NOTEBOOK SELESAI!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
